{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497489a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25a0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for each fracture type\n",
    "root = 'data/'\n",
    "paths = {\n",
    "    'Hairline Fracture': root + 'Hairline Fracture/Train',\n",
    "    'Spiral Fracture': root + 'Spiral Fracture/Train',\n",
    "    'Greenstick Fracture': root + 'Greenstick fracture/Train',\n",
    "    'Comminuted Fracture': root + 'Comminuted fracture/Train',\n",
    "    'Fracture Dislocation': root + 'Fracture Dislocation/Train',\n",
    "    'Pathological Fracture': root + 'Pathological fracture/Train',\n",
    "    'Longitudinal Fracture': root + 'Longitudinal fracture/Train',\n",
    "    'Oblique Fracture': root + 'Oblique fracture/Train',\n",
    "    'Impacted Fracture': root + 'Impacted fracture/Train',\n",
    "    'Avulsion Fracture': root + 'Avulsion fracture/Train'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecda14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess an image\n",
    "def load_image(image_path, image_size=(512, 512)):\n",
    "    # Read the image from the file\n",
    "    image = tf.io.read_file(image_path)\n",
    "    \n",
    "    # Decode the JPEG image into a tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    \n",
    "    # Resize the image to the desired size\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    \n",
    "    # Convert image to numpy array and scale pixel values to [0, 255]\n",
    "    image = (image.numpy() * 255).astype('uint8')\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    equalized_image = cv2.equalizeHist(gray_image)\n",
    "    \n",
    "    return equalized_image\n",
    "\n",
    "def create_2d_gaussian(size, sigma):\n",
    "    # Create a linear space from -size//2 to size//2\n",
    "    ax = np.linspace(-(size // 2), size // 2, size)\n",
    "    # Create a meshgrid from the linear space\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    # Calculate the Gaussian kernel\n",
    "    kernel = np.exp(-0.5 * (np.square(xx) + np.square(yy)) / np.square(sigma))\n",
    "    # Normalize the kernel so that the sum is 1\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def convolve2d(image, kernel):\n",
    "    # Flip the kernel for convolution\n",
    "    kernel = kernel[::-1, ::-1]\n",
    "    # Create an output array of the same shape as the input image\n",
    "    output = np.zeros_like(image)\n",
    "    # Pad the input image to handle borders\n",
    "    image_padded = np.pad(image, [(kernel.shape[0]//2, kernel.shape[0]//2), \n",
    "                                  (kernel.shape[1]//2, kernel.shape[1]//2)], mode='reflect')\n",
    "    # Loop over each pixel in the image\n",
    "    for x in range(image.shape[1]):\n",
    "        for y in range(image.shape[0]):\n",
    "            # Perform element-wise multiplication and sum the results\n",
    "            output[y, x] = (kernel * image_padded[y:y+kernel.shape[0], x:x+kernel.shape[1]]).sum()\n",
    "    return output\n",
    "\n",
    "def gaussian_and_laplacian_stack(img, levels, size=17, sigma=3):\n",
    "    # Initialize the Gaussian stack with the original image\n",
    "    gaussian_stack = [img]\n",
    "    # Initialize the Laplacian stack\n",
    "    laplacian_stack = []\n",
    "\n",
    "    # Loop to create each level of the Gaussian and Laplacian stacks\n",
    "    for i in range(1, levels):\n",
    "        # Create the Gaussian kernel\n",
    "        gaussian_kernel = create_2d_gaussian(size, sigma)\n",
    "        # Convolve the last image in the Gaussian stack with the Gaussian kernel\n",
    "        gaussian = convolve2d(gaussian_stack[-1], gaussian_kernel)\n",
    "        # Append the resulting image to the Gaussian stack\n",
    "        gaussian_stack.append(gaussian)\n",
    "        # Calculate the Laplacian image by subtracting the current Gaussian image from the previous one\n",
    "        laplacian = gaussian_stack[-2] - gaussian\n",
    "        # Append the Laplacian image to the Laplacian stack\n",
    "        laplacian_stack.append(laplacian)\n",
    "\n",
    "    # The last level of the Laplacian stack is the last image in the Gaussian stack\n",
    "    laplacian_stack.append(gaussian_stack[-1])\n",
    "    return gaussian_stack, laplacian_stack\n",
    "\n",
    "def visualize_stack(in_stack, title):\n",
    "    # Create a figure with subplots for each level in the stack\n",
    "    fig, axes = plt.subplots(1, len(in_stack), figsize=(15, 10))\n",
    "    # Loop over each level and corresponding subplot axis\n",
    "    for i, (ax, img) in enumerate(zip(axes, in_stack)):\n",
    "        # Display the image on the axis\n",
    "        ax.imshow(img, cmap='gray', vmin=np.min(img), vmax=np.max(img))\n",
    "        # Set the title of the subplot to indicate the level\n",
    "        ax.set_title(f'Level {i+1}')\n",
    "        # Remove the axis ticks and labels\n",
    "        ax.axis('off')\n",
    "    # Set the overall title for the figure\n",
    "    fig.suptitle(title)\n",
    "    # Show the figure\n",
    "    plt.show()\n",
    "\n",
    "# Custom feature extraction functions\n",
    "def extract_hog_features(image):\n",
    "    # Extract HOG features and the HOG image\n",
    "    fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "                        cells_per_block=(2, 2), visualize=True)\n",
    "    return fd, hog_image\n",
    "\n",
    "def extract_canny_edges(image):\n",
    "\n",
    "    # Extract Canny edges\n",
    "    edges = cv2.Canny(image, threshold1=100, threshold2=200)\n",
    "    return edges.ravel(), edges\n",
    "\n",
    "def extract_contours(image):\n",
    "\n",
    "    # Apply a binary threshold to the grayscale image\n",
    "    ret, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Initialize a list to store contour features\n",
    "    contour_features = []\n",
    "    # Loop over the first 5 contours\n",
    "    for contour in contours[:5]:\n",
    "        # Calculate the moments of the contour\n",
    "        moments = cv2.moments(contour)\n",
    "        # Calculate the Hu moments and flatten them\n",
    "        hu_moments = cv2.HuMoments(moments).flatten()\n",
    "        # Append the Hu moments to the contour features list\n",
    "        contour_features.extend(hu_moments)\n",
    "    return np.array(contour_features), contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f6d8b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to Fracture Mapping:\n",
      "0: Hairline Fracture\n",
      "1: Spiral Fracture\n",
      "2: Greenstick Fracture\n",
      "3: Comminuted Fracture\n",
      "4: Fracture Dislocation\n",
      "5: Pathological Fracture\n",
      "6: Longitudinal Fracture\n",
      "7: Oblique Fracture\n",
      "8: Impacted Fracture\n",
      "9: Avulsion Fracture\n"
     ]
    }
   ],
   "source": [
    "# Print label to fracture mapping\n",
    "label_to_fracture = {label: fracture for label, fracture in enumerate(paths.keys())}\n",
    "print(\"Label to Fracture Mapping:\")\n",
    "for label, fracture in label_to_fracture.items():\n",
    "    print(f\"{label}: {fracture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15107d0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m first_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_path, image_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Visualize the features for the first image\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[43mvisualize_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mvisualize_features\u001b[1;34m(image_path, class_name)\u001b[0m\n\u001b[0;32m      9\u001b[0m contour_features, contours \u001b[38;5;241m=\u001b[39m extract_contours(image)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create Gaussian and Laplacian stacks for the image\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m gaussian_stack, laplacian_stack \u001b[38;5;241m=\u001b[39m gaussian_and_laplacian_stack(\u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Plot the original image and the extracted features\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "# Function to visualize features\n",
    "def visualize_features(image_path, class_name):\n",
    "    # Load and preprocess the image\n",
    "    image = load_image(image_path)\n",
    "\n",
    "    # Extract features using the defined functions\n",
    "    hog_features, hog_image = extract_hog_features(image)\n",
    "    canny_features, canny_image = extract_canny_edges(image)\n",
    "    contour_features, contours = extract_contours(image)\n",
    "    # Create Gaussian and Laplacian stacks for the image\n",
    "    gaussian_stack, laplacian_stack = gaussian_and_laplacian_stack(image[:, :, 0], levels=6)\n",
    "\n",
    "    # Plot the original image and the extracted features\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.title(f'Original Image: {class_name}')\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.title('HOG Image')\n",
    "    plt.imshow(hog_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.title('Canny Edges')\n",
    "    plt.imshow(canny_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.title('Contours')\n",
    "    plt.imshow(cv2.drawContours(image_np.copy(), contours, -1, (0, 255, 0), 2))\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Visualize the Gaussian and Laplacian stacks\n",
    "    visualize_stack(gaussian_stack, title=f'Gaussian Stack: {class_name}')\n",
    "    visualize_stack(laplacian_stack, title=f'Laplacian Stack: {class_name}')\n",
    "\n",
    "# Visualize features for an image in each class\n",
    "for class_name, class_path in paths.items():\n",
    "    # List all image files in the directory\n",
    "    image_files = tf.io.gfile.listdir(class_path)\n",
    "    # If there are any images in the directory\n",
    "    if image_files:\n",
    "        # Get the path to the first image\n",
    "        first_image_path = os.path.join(class_path, image_files[0])\n",
    "        # Visualize the features for the first image\n",
    "        visualize_features(first_image_path, class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5147a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d14388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: min=58, max=640, mean=429.5490394337715, median=443.0\n",
      "Height: min=77, max=640, mean=561.4509605662286, median=640.0\n"
     ]
    }
   ],
   "source": [
    "# Function to get image dimensions\n",
    "def get_image_dimensions(image_path):\n",
    "    \"\"\"\n",
    "    Get dimensions of an image.\n",
    "\n",
    "    Args:\n",
    "    - image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Width and height of the image.\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    return image.shape[1], image.shape[0]\n",
    "\n",
    "# Lists to store image dimensions\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "# Loop over each class and its images\n",
    "for class_name, class_path in paths.items():\n",
    "    # List all image files in the directory\n",
    "    image_files = tf.io.gfile.listdir(class_path)\n",
    "    # Loop over each image file\n",
    "    for image_file in image_files:\n",
    "        # Get the full path to the image\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        # Get the dimensions of the image\n",
    "        width, height = get_image_dimensions(image_path)\n",
    "        # Append the dimensions to the lists\n",
    "        widths.append(width)\n",
    "        heights.append(height)\n",
    "\n",
    "# Convert lists to numpy arrays for easier analysis\n",
    "widths = np.array(widths)\n",
    "heights = np.array(heights)\n",
    "\n",
    "# Calculate statistics\n",
    "min_width = np.min(widths)\n",
    "max_width = np.max(widths)\n",
    "mean_width = np.mean(widths)\n",
    "median_width = np.median(widths)\n",
    "\n",
    "min_height = np.min(heights)\n",
    "max_height = np.max(heights)\n",
    "mean_height = np.mean(heights)\n",
    "median_height = np.median(heights)\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Width: min={min_width}, max={max_width}, mean={mean_width}, median={median_width}\")\n",
    "print(f\"Height: min={min_height}, max={max_height}, mean={mean_height}, median={median_height}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
