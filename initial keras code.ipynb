{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4bc81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Define paths for each fracture type\n",
    "root = 'data/'\n",
    "paths = {\n",
    "    'Hairline Fracture': root + 'Hairline Fracture/Train',\n",
    "    'Spiral Fracture': root + 'Spiral Fracture/Train',\n",
    "    'Greenstick Fracture': root + 'Greenstick fracture/Train',\n",
    "    'Comminuted Fracture': root + 'Comminuted fracture/Train',\n",
    "    'Fracture Dislocation': root + 'Fracture Dislocation/Train',\n",
    "    'Pathological Fracture': root + 'Pathological fracture/Train',\n",
    "    'Longitudinal Fracture': root + 'Longitudinal fracture/Train',\n",
    "    'Oblique Fracture': root + 'Oblique fracture/Train',\n",
    "    'Impacted Fracture': root + 'Impacted fracture/Train',\n",
    "    'Avulsion Fracture': root + 'Avulsion fracture/Train'\n",
    "}\n",
    "\n",
    "# Load and label the dataset\n",
    "def load_and_label_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image, label\n",
    "\n",
    "def get_dataset(paths):\n",
    "    datasets = []\n",
    "    for label, (fracture_type, path) in enumerate(paths.items()):\n",
    "        list_ds = tf.data.Dataset.list_files(path + '/*.jpg', shuffle=False)\n",
    "        labeled_ds = list_ds.map(lambda x: load_and_label_image(x, label), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        datasets.append(labeled_ds)\n",
    "    return datasets\n",
    "\n",
    "train_datasets = get_dataset(paths)\n",
    "train_dataset = train_datasets[0]\n",
    "for dataset in train_datasets[1:]:\n",
    "    train_dataset = train_dataset.concatenate(dataset)\n",
    "\n",
    "# Shuffle the dataset for performance\n",
    "train_dataset = train_dataset.shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Define maximum lengths for features\n",
    "HOG_FEATURE_LENGTH = 7744  # Example length for HOG features\n",
    "CANNY_FEATURE_LENGTH = 65536  # Example length for Canny edge features\n",
    "CONTOUR_FEATURE_LENGTH = 7 * 5  # Example length for contour features (7 Hu moments * 5 contours)\n",
    "FREQUENCY_FEATURE_LENGTH = 65536  # Example length for frequency components\n",
    "\n",
    "def pad_or_truncate(features, length):\n",
    "    if len(features) > length:\n",
    "        return features[:length]\n",
    "    else:\n",
    "        return np.pad(features, (0, length - len(features)), 'constant')\n",
    "\n",
    "# Custom feature extraction functions\n",
    "def extract_hog_features(image):\n",
    "    image = (image * 255).numpy().astype('uint8')\n",
    "    fd = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "             cells_per_block=(2, 2), visualize=False, channel_axis=-1)\n",
    "    return pad_or_truncate(fd, HOG_FEATURE_LENGTH)\n",
    "\n",
    "def extract_canny_edges(image):\n",
    "    image = (image * 255).numpy().astype('uint8')\n",
    "    edges = cv2.Canny(image, threshold1=100, threshold2=200)\n",
    "    return pad_or_truncate(edges.ravel(), CANNY_FEATURE_LENGTH)\n",
    "\n",
    "def extract_contours(image):\n",
    "    image = (image * 255).numpy().astype('uint8')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_features = []\n",
    "    for contour in contours[:5]:  # Limit to the first 5 contours\n",
    "        moments = cv2.moments(contour)\n",
    "        hu_moments = cv2.HuMoments(moments).flatten()\n",
    "        contour_features.extend(hu_moments)\n",
    "    return pad_or_truncate(np.array(contour_features), CONTOUR_FEATURE_LENGTH)\n",
    "\n",
    "def extract_frequency_components(image):\n",
    "    image = (image * 255).numpy().astype('uint8')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    f = np.fft.fft2(gray)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20 * np.log(np.abs(fshift))\n",
    "    return pad_or_truncate(magnitude_spectrum.ravel(), FREQUENCY_FEATURE_LENGTH)\n",
    "\n",
    "def extract_features(image, label):\n",
    "    hog_features = extract_hog_features(image)\n",
    "    canny_features = extract_canny_edges(image)\n",
    "    contour_features = extract_contours(image)\n",
    "    frequency_features = extract_frequency_components(image)\n",
    "    combined_features = np.concatenate([hog_features, canny_features, contour_features, frequency_features])\n",
    "    return combined_features, label\n",
    "\n",
    "def feature_extraction(image, label):\n",
    "    image, label = tf.py_function(extract_features, [image, label], [tf.float32, tf.int32])\n",
    "    feature_length = HOG_FEATURE_LENGTH + CANNY_FEATURE_LENGTH + CONTOUR_FEATURE_LENGTH + FREQUENCY_FEATURE_LENGTH\n",
    "    image.set_shape([feature_length])  # Set the shape to the fixed feature length\n",
    "    label.set_shape([])  # Set the shape for the label\n",
    "    return image, label\n",
    "\n",
    "# Apply feature extraction\n",
    "train_dataset = train_dataset.map(feature_extraction, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch the dataset after feature extraction\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Define and compile a simple neural network model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(HOG_FEATURE_LENGTH + CANNY_FEATURE_LENGTH + CONTOUR_FEATURE_LENGTH + FREQUENCY_FEATURE_LENGTH,)),  # Set input_shape based on combined feature length\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Adjust based on the number of classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=10)\n",
    "\n",
    "# Verify the shape of the feature matrix and labels\n",
    "for features_batch, labels_batch in train_dataset.take(1):\n",
    "    print('Features batch shape:', features_batch.shape)\n",
    "    print('Labels batch shape:', labels_batch.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
