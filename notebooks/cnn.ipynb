{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 21:04:16.074077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-28 21:04:16.087331: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-28 21:04:16.087350: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-28 21:04:16.096854: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-28 21:04:16.758427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 21:04:17.633457: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 21:04:17.667029: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 21:04:17.669876: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = np.expand_dims(np.load(\"../data/images/images_train.npy\") / 255.0, -1)\n",
    "images_test = np.expand_dims(np.load(\"../data/images/images_test.npy\") / 255.0, -1)\n",
    "num_samples_train = images_train.shape[0]\n",
    "num_samples_test = images_test.shape[0]\n",
    "\n",
    "y_train = np.load(\"../data/images/label_ids_train.npy\")\n",
    "y_test = np.load(\"../data/images/label_ids_test.npy\")\n",
    "\n",
    "train_indices = np.random.permutation(num_samples_train)\n",
    "images_train = images_train[train_indices]\n",
    "y_train = y_train[train_indices]\n",
    "\n",
    "test_indices = np.random.permutation(num_samples_test)\n",
    "images_test = images_test[test_indices]\n",
    "y_test = y_test[test_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 'dislocation',\n",
       " 2: 'greenstick',\n",
       " 8: 'impacted',\n",
       " 9: 'avulsion',\n",
       " 1: 'spiral',\n",
       " 6: 'longitudinal',\n",
       " 7: 'oblique',\n",
       " 3: 'comminuted',\n",
       " 5: 'pathological',\n",
       " 0: 'hairline'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train = np.load(\"../data/images/labels_train.npy\")\n",
    "class_lookup = list(set(zip(y_train, labels_train)))\n",
    "class_lookup = {id_value: class_value for id_value, class_value in class_lookup}\n",
    "class_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = layers.Input(shape=(images_train.shape[1], images_train.shape[2], images_train.shape[3]))\n",
    "x = layers.Conv2D(60, (3, 3), activation='relu')(image_input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(120, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(40, activation='relu')(x)\n",
    "output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=[image_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(images_train[train], y_train[train],\n",
    "            batch_size=32,\n",
    "            epochs=5,\n",
    "            verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 21:04:18.071907: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 21:04:18.074601: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 21:04:18.076795: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 21:04:18.204419: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 21:04:18.205891: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 21:04:18.207289: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 21:04:18.208643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9660 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722215060.687718   49297 service.cc:145] XLA service 0x7023540038c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722215060.687773   49297 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-07-28 21:04:20.708595: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-28 21:04:20.800954: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n",
      "2024-07-28 21:04:29.151330: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=0,k5=2,k14=4} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,512,512]{3,2,1,0}, f32[32,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-28 21:04:30.268762: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.117513863s\n",
      "Trying algorithm eng46{k2=0,k5=2,k14=4} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,512,512]{3,2,1,0}, f32[32,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-28 21:04:31.268890: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng23{k2=0,k13=2,k14=3,k18=1,k23=0} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,512,512]{3,2,1,0}, f32[32,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-28 21:04:32.374851: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.106032017s\n",
      "Trying algorithm eng23{k2=0,k13=2,k14=3,k18=1,k23=0} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,512,512]{3,2,1,0}, f32[32,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/21\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.0625 - loss: 8.5148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722215077.151889   49297 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.1160 - loss: 8.4314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 21:04:44.909545: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=0,k5=2,k14=4} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,1,512,512]{3,2,1,0}, f32[19,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-28 21:04:45.148112: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.238631916s\n",
      "Trying algorithm eng46{k2=0,k5=2,k14=4} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,1,512,512]{3,2,1,0}, f32[19,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-28 21:04:46.148262: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng23{k2=0,k13=2,k14=3,k18=1,k23=0} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,1,512,512]{3,2,1,0}, f32[19,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-28 21:04:46.430016: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.281819096s\n",
      "Trying algorithm eng23{k2=0,k13=2,k14=3,k18=1,k23=0} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[19,1,512,512]{3,2,1,0}, f32[19,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 638ms/step - accuracy: 0.1171 - loss: 8.1117\n",
      "Epoch 2/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.2424 - loss: 2.1674\n",
      "Epoch 3/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.4375 - loss: 1.7388\n",
      "Epoch 4/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.7209 - loss: 1.0109\n",
      "Epoch 5/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.9194 - loss: 0.3817\n",
      "Score for fold 1: loss of 3.7139666080474854; compile_metrics of 26.66666805744171%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.1021 - loss: 8.0677\n",
      "Epoch 2/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.1420 - loss: 2.2815\n",
      "Epoch 3/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.2304 - loss: 2.1209\n",
      "Epoch 4/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.4439 - loss: 1.6455\n",
      "Epoch 5/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.7252 - loss: 0.9215\n",
      "Score for fold 2: loss of 2.9691946506500244; compile_metrics of 26.0606050491333%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/5\n",
      "\u001b[1m20/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.0945 - loss: 11.4178"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 21:05:27.228149: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=0,k5=2,k14=4} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,1,512,512]{3,2,1,0}, f32[20,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-28 21:05:27.459908: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.231833438s\n",
      "Trying algorithm eng46{k2=0,k5=2,k14=4} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,1,512,512]{3,2,1,0}, f32[20,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-28 21:05:28.460037: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng23{k2=0,k13=2,k14=3,k18=1,k23=0} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,1,512,512]{3,2,1,0}, f32[20,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-28 21:05:28.739584: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.279621523s\n",
      "Trying algorithm eng23{k2=0,k13=2,k14=3,k18=1,k23=0} for conv (f32[60,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[20,1,512,512]{3,2,1,0}, f32[20,60,510,510]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 678ms/step - accuracy: 0.0962 - loss: 10.9666\n",
      "Epoch 2/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.1811 - loss: 2.2685\n",
      "Epoch 3/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.3096 - loss: 2.1270\n",
      "Epoch 4/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.4852 - loss: 1.6075\n",
      "Epoch 5/5\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.7768 - loss: 0.8818\n",
      "Score for fold 3: loss of 2.609377861022949; compile_metrics of 24.012157320976257%\n"
     ]
    }
   ],
   "source": [
    "# # Define the K-fold Cross Validator\n",
    "# kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# # K-fold Cross Validation model evaluation\n",
    "# fold_no = 1\n",
    "# acc_per_fold = []\n",
    "# loss_per_fold = []\n",
    "# for train, test in kfold.split(images_train, y_train):\n",
    "\n",
    "#     image_input = layers.Input(shape=(images_train.shape[1], images_train.shape[2], images_train.shape[3]))\n",
    "#     x = layers.Conv2D(60, (3, 3), activation='relu')(image_input)\n",
    "#     x = layers.MaxPooling2D((2, 2))(x)\n",
    "#     x = layers.Conv2D(120, (3, 3), activation='relu')(x)\n",
    "#     x = layers.MaxPooling2D((2, 2))(x)\n",
    "#     x = layers.Flatten()(x)\n",
    "    \n",
    "#     x = layers.Dense(40, activation='relu')(x)\n",
    "#     output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "#     model = models.Model(inputs=[image_input], outputs=output)\n",
    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     # Generate a print\n",
    "#     print('------------------------------------------------------------------------')\n",
    "#     print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "#     # Fit data to model\n",
    "#     history = model.fit(images_train[train], y_train[train],\n",
    "#               batch_size=32,\n",
    "#               epochs=5,\n",
    "#               verbose=1)\n",
    "    \n",
    "#     # Generate generalization metrics\n",
    "#     scores = model.evaluate(images_train[test], y_train[test], verbose=0)\n",
    "#     print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "#     acc_per_fold.append(scores[1] * 100)\n",
    "#     loss_per_fold.append(scores[0])\n",
    "    \n",
    "#     # Increase fold number\n",
    "#     fold_no = fold_no + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285ms/step\n",
      "Accuracy: 0.17857142857142858\n",
      "Classification Report:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hairline</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spiral</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greenstick</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comminuted</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dislocation</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pathological</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitudinal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oblique</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impacted</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avulsion</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.157459</td>\n",
       "      <td>0.163523</td>\n",
       "      <td>0.157512</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.168829</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.170804</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "hairline       0.000000  0.000000  0.000000   10.000000\n",
       "spiral         0.200000  0.166667  0.181818   12.000000\n",
       "greenstick     0.277778  0.312500  0.294118   16.000000\n",
       "comminuted     0.166667  0.285714  0.210526   14.000000\n",
       "dislocation    0.272727  0.315789  0.292683   19.000000\n",
       "pathological   0.176471  0.166667  0.171429   18.000000\n",
       "longitudinal   0.000000  0.000000  0.000000   12.000000\n",
       "oblique        0.100000  0.062500  0.076923   16.000000\n",
       "impacted       0.166667  0.111111  0.133333    9.000000\n",
       "avulsion       0.214286  0.214286  0.214286   14.000000\n",
       "accuracy       0.178571  0.178571  0.178571    0.178571\n",
       "macro avg      0.157459  0.163523  0.157512  140.000000\n",
       "weighted avg   0.168829  0.178571  0.170804  140.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([images_test])\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report = pd.DataFrame(report).transpose()\n",
    "report.index = report.index.map(lambda x: class_lookup[int(x)] if x.isdigit() else x)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
